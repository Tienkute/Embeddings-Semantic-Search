from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import datetime

class SemanticSearchSystem:
    def __init__(self):
        # 1. Kh·ªüi t·∫°o Model (Embedding Basics)
        print("--- ƒêang kh·ªüi ƒë·ªông h·ªá th·ªëng AI... ---")
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        self.memory = [] # L∆∞u l·ªãch s·ª≠ t√¨m ki·∫øm (Memory)
        
        # 2. Kho d·ªØ li·ªáu m·∫´u (Document Store)
        self.documents = [
            "Python l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh m·∫°nh m·∫Ω cho AI v√† Web.",
            "GitHub gi√∫p qu·∫£n l√Ω m√£ ngu·ªìn v√† l√†m vi·ªác nh√≥m hi·ªáu qu·∫£.",
            "Embedding bi·∫øn vƒÉn b·∫£n th√†nh c√°c vector s·ªë ƒë·ªÉ m√°y t√≠nh hi·ªÉu ng·ªØ nghƒ©a.",
            "H·ªá th·ªëng RAG k·∫øt h·ª£p t√¨m ki·∫øm d·ªØ li·ªáu v√† t·∫°o vƒÉn b·∫£n t·ª± ƒë·ªông.",
            "H·ªçc m√°y (Machine Learning) l√† m·ªôt t·∫≠p con c·ªßa Tr√≠ tu·ªá nh√¢n t·∫°o."
        ]
        # Chuy·ªÉn kho d·ªØ li·ªáu th√†nh Vector s·∫µn ƒë·ªÉ t√¨m ki·∫øm nhanh h∆°n
        self.doc_embeddings = self.model.encode(self.documents)

    def search(self, query):
        """Th·ª±c hi·ªán t√¨m ki·∫øm t∆∞∆°ng ƒë·ªìng (Similarity Search)"""
        query_vec = self.model.encode([query])
        # T√≠nh to√°n Cosine Similarity
        scores = cosine_similarity(query_vec, self.doc_embeddings)[0]
        best_index = np.argmax(scores)
        return self.documents[best_index], scores[best_index]

    def process_query(self, user_query):
        """ƒêi·ªÅu h∆∞·ªõng v√† x·ª≠ l√Ω c√¢u h·ªèi (Memory + Routing)"""
        # L∆∞u v√†o l·ªãch s·ª≠ (Memory)
        timestamp = datetime.datetime.now().strftime("%H:%M:%S")
        self.memory.append({"time": timestamp, "query": user_query})

        # Logic ƒëi·ªÅu h∆∞·ªõng (Routing)
        words = user_query.split()
        
        if len(words) < 4:
            # C√¢u h·ªèi ng·∫Øn -> T√¨m ki·∫øm ng·ªØ nghƒ©a tr·ª±c ti·∫øp
            print(f"\n[ROUTING]: C√¢u h·ªèi ng·∫Øn -> Ch·∫ø ƒë·ªô T√¨m ki·∫øm nhanh")
            result, score = self.search(user_query)
            print(f"üîç K·∫øt qu·∫£: {result} (ƒê·ªô kh·ªõp: {score*100:.2f}%)")
        else:
            # C√¢u h·ªèi d√†i -> Ch·∫ø ƒë·ªô ph√¢n t√≠ch/gi·∫£i th√≠ch
            print(f"\n[ROUTING]: C√¢u h·ªèi d√†i -> Ch·∫ø ƒë·ªô Ph√¢n t√≠ch chuy√™n s√¢u")
            result, score = self.search(user_query)
            print(f"üí° H·ªá th·ªëng ƒë·ªÅ xu·∫•t: {result}")
            print(f"üìù Gi·∫£i th√≠ch: D·ª±a tr√™n ph√¢n t√≠ch, c√¢u h·ªèi '{user_query}' c√≥ li√™n quan m·∫≠t thi·∫øt nh·∫•t ƒë·∫øn n·ªôi dung n√†y.")

    def show_history(self):
        """Hi·ªÉn th·ªã l·ªãch s·ª≠ (Summarize memory)"""
        print("\n--- L·ªäCH S·ª¨ T√åM KI·∫æM ---")
        for item in self.memory:
            print(f"[{item['time']}] {item['query']}")

# --- CH·∫†Y CH∆Ø∆†NG TR√åNH ---
if __name__ == "__main__":
    app = SemanticSearchSystem()
    
    # Test 1: C√¢u h·ªèi ng·∫Øn (Routing sang Search)
    app.process_query("L·∫≠p tr√¨nh Python")
    
    # Test 2: C√¢u h·ªèi d√†i (Routing sang Refinement/Explanation)
    app.process_query("L√†m th·∫ø n√†o ƒë·ªÉ qu·∫£n l√Ω m√£ ngu·ªìn m·ªôt c√°ch hi·ªáu qu·∫£ nh·∫•t?")
    
    # Hi·ªÉn th·ªã l·ªãch s·ª≠
    app.show_history()
